#!/usr/bin/env python3
"""
æ•°æ®é›†åˆå¹¶è„šæœ¬
åˆå¹¶ merged_features_labels.csv å’Œ GSE25097.csv
åªä¿ç•™ä¸¤ä¸ªæ•°æ®é›†çš„äº¤é›†ç‰¹å¾ï¼ˆåˆ—ï¼‰ï¼Œå¹¶è°ƒæ•´æ ‡ç­¾ç¼–ç 
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
from sklearn.model_selection import train_test_split

def merge_datasets(file1_path, file2_path, output_path):
    """
    åˆå¹¶ä¸¤ä¸ªCSVæ•°æ®é›†ï¼Œåªä¿ç•™äº¤é›†ç‰¹å¾
    
    Args:
        file1_path: merged_features_labels.csv è·¯å¾„
        file2_path: GSE25097.csv è·¯å¾„  
        output_path: åˆå¹¶åçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    
    print("ğŸ”„ å¼€å§‹åˆå¹¶æ•°æ®é›†...")
    
    # è¯»å–ç¬¬ä¸€ä¸ªæ•°æ®é›† (merged_features_labels.csv)
    print(f"ğŸ“Š è¯»å–ç¬¬ä¸€ä¸ªæ•°æ®é›†: {file1_path}")
    df1 = pd.read_csv(file1_path, index_col=0)
    print(f"   - æ ·æœ¬æ•°: {len(df1)}")
    print(f"   - ç‰¹å¾æ•°: {len(df1.columns) - 1} (ä¸å«Label)")
    
    # è¯»å–ç¬¬äºŒä¸ªæ•°æ®é›† (GSE25097.csv)
    print(f"ğŸ“Š è¯»å–ç¬¬äºŒä¸ªæ•°æ®é›†: {file2_path}")
    df2 = pd.read_csv(file2_path, index_col=0)
    print(f"   - æ ·æœ¬æ•°: {len(df2)}")
    print(f"   - ç‰¹å¾æ•°: {len(df2.columns) - 1} (ä¸å«Label)")
    
    # æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒ
    print("\nğŸ·ï¸ åŸå§‹æ ‡ç­¾åˆ†å¸ƒ:")
    print("æ•°æ®é›†1 (merged_features_labels.csv):")
    if 'Label' in df1.columns:
        label_col1 = 'Label'
    else:
        # å‡è®¾æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾åˆ—
        label_col1 = df1.columns[-1]
    print(f"   {df1[label_col1].value_counts().to_dict()}")
    
    print("æ•°æ®é›†2 (GSE25097.csv):")
    if 'Label' in df2.columns:
        label_col2 = 'Label'
    else:
        # å‡è®¾æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾åˆ—
        label_col2 = df2.columns[-1]
    print(f"   {df2[label_col2].value_counts().to_dict()}")
    
    # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
    features1 = df1.drop(columns=[label_col1])
    labels1 = df1[label_col1]
    
    features2 = df2.drop(columns=[label_col2])  
    labels2 = df2[label_col2]
    
    # æ‰¾åˆ°äº¤é›†ç‰¹å¾
    common_features = list(set(features1.columns) & set(features2.columns))
    print(f"\nğŸ”— æ‰¾åˆ°äº¤é›†ç‰¹å¾: {len(common_features)} ä¸ª")
    print(f"   æ•°æ®é›†1ç‹¬æœ‰ç‰¹å¾: {len(features1.columns) - len(common_features)} ä¸ª")
    print(f"   æ•°æ®é›†2ç‹¬æœ‰ç‰¹å¾: {len(features2.columns) - len(common_features)} ä¸ª")
    
    if len(common_features) == 0:
        raise ValueError("âŒ é”™è¯¯ï¼šä¸¤ä¸ªæ•°æ®é›†æ²¡æœ‰å…±åŒçš„ç‰¹å¾åˆ—ï¼")
    
    # åªä¿ç•™äº¤é›†ç‰¹å¾
    features1_common = features1[common_features]
    features2_common = features2[common_features]
    
    # å¤„ç†æ ‡ç­¾ç¼–ç 
    print("\nğŸ”„ å¤„ç†æ ‡ç­¾ç¼–ç ...")
    
    # æ•°æ®é›†1: å°†å­—ç¬¦ä¸²æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼
    # "Normal" -> 0, "HBV-HCC" -> 1
    labels1_numeric = labels1.map({
        "Normal": 0,
        "HBV-HCC": 1
    })
    
    # æ•°æ®é›†2: å°†æ ‡ç­¾1è½¬æ¢ä¸º2ï¼Œä¿æŒ0ä¸å˜
    # 0 -> 0, 1 -> 2  
    labels2_numeric = labels2.map({0: 0, 1: 2})
    
    print("å¤„ç†åæ ‡ç­¾åˆ†å¸ƒ:")
    print(f"   æ•°æ®é›†1: {dict(labels1_numeric.value_counts().sort_index())}")
    print(f"   æ•°æ®é›†2: {dict(labels2_numeric.value_counts().sort_index())}")
    
    # é‡æ–°æ·»åŠ æ ‡ç­¾åˆ—
    features1_common['Label'] = labels1_numeric
    features2_common['Label'] = labels2_numeric
    
    # åˆå¹¶æ•°æ®é›†
    print(f"\nğŸ”€ åˆå¹¶æ•°æ®é›†...")
    merged_df = pd.concat([features1_common, features2_common], axis=0, ignore_index=False)
    
    print(f"âœ… åˆå¹¶å®Œæˆ:")
    print(f"   - æ€»æ ·æœ¬æ•°: {len(merged_df)}")
    print(f"   - ç‰¹å¾æ•°: {len(merged_df.columns) - 1} (ä¸å«Label)")
    print(f"   - æœ€ç»ˆæ ‡ç­¾åˆ†å¸ƒ: {dict(merged_df['Label'].value_counts().sort_index())}")
    
    # ä¿å­˜åˆå¹¶åçš„æ•°æ®é›†
    print(f"\nğŸ’¾ ä¿å­˜å®Œæ•´æ•°æ®é›†åˆ°: {output_path}")
    merged_df.to_csv(output_path, index=True)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›† (8:2)
    print("\nğŸ”„ æŒ‰8:2æ¯”ä¾‹åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†...")
    
    # ä¸ºäº†ä¿æŒç±»åˆ«å¹³è¡¡ï¼Œä½¿ç”¨åˆ†å±‚æŠ½æ ·
    X = merged_df.drop('Label', axis=1)
    y = merged_df['Label']
    
    # åˆ†å±‚æŠ½æ ·ç¡®ä¿è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸­å„ç±»åˆ«æ¯”ä¾‹ç›¸åŒ
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # é‡æ–°ç»„åˆç‰¹å¾å’Œæ ‡ç­¾
    train_df = X_train.copy()
    train_df['Label'] = y_train
    
    val_df = X_val.copy()
    val_df['Label'] = y_val
    
    # ä¿å­˜è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_path = str(output_path).replace('.csv', '_train.csv')
    val_path = str(output_path).replace('.csv', '_valid.csv')
    
    print(f"ğŸ’¾ ä¿å­˜è®­ç»ƒé›†åˆ°: {train_path}")
    train_df.to_csv(train_path, index=True)
    
    print(f"ğŸ’¾ ä¿å­˜éªŒè¯é›†åˆ°: {val_path}")
    val_df.to_csv(val_path, index=True)
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    report = f"""
=== æ•°æ®é›†åˆå¹¶å’Œåˆ†å‰²æŠ¥å‘Š ===
è¾“å…¥æ–‡ä»¶:
  - æ•°æ®é›†1: {file1_path}
  - æ•°æ®é›†2: {file2_path}

åˆå¹¶ç»“æœ:
  - å®Œæ•´æ•°æ®é›†: {output_path} ({len(merged_df)} æ ·æœ¬)
  - è®­ç»ƒé›†: {train_path} ({len(train_df)} æ ·æœ¬, {len(train_df)/len(merged_df)*100:.1f}%)
  - éªŒè¯é›†: {val_path} ({len(val_df)} æ ·æœ¬, {len(val_df)/len(merged_df)*100:.1f}%)
  - å…±åŒç‰¹å¾æ•°: {len(common_features)}
  
æ ‡ç­¾ç¼–ç :
  - 0: æ­£å¸¸/éè‚¿ç˜¤æ ·æœ¬
  - 1: HBV-HCCæ ·æœ¬  
  - 2: å…¶ä»–è‚¿ç˜¤æ ·æœ¬

æ ‡ç­¾åˆ†å¸ƒ:
  å®Œæ•´æ•°æ®é›†: {dict(merged_df['Label'].value_counts().sort_index())}
  è®­ç»ƒé›†: {dict(train_df['Label'].value_counts().sort_index())}
  éªŒè¯é›†: {dict(val_df['Label'].value_counts().sort_index())}

æ•°æ®æ¥æº:
  - Label 0: æ¥è‡ªä¸¤ä¸ªæ•°æ®é›†çš„æ­£å¸¸/éè‚¿ç˜¤æ ·æœ¬
  - Label 1: æ¥è‡ª merged_features_labels.csv çš„ HBV-HCC æ ·æœ¬
  - Label 2: æ¥è‡ª GSE25097.csv çš„è‚¿ç˜¤æ ·æœ¬
"""
    
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = str(output_path).replace('.csv', '_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    return merged_df, train_df, val_df

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    current_dir = Path(__file__).parent
    file1_path = current_dir / "merged_features_labels.csv"
    file2_path = current_dir / "GSE25097.csv"
    output_path = current_dir / "combined_dataset.csv"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file1_path.exists():
        raise FileNotFoundError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file1_path}")
    if not file2_path.exists():
        raise FileNotFoundError(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file2_path}")
    
    try:
        # æ‰§è¡Œåˆå¹¶å’Œåˆ†å‰²
        merged_df, train_df, val_df = merge_datasets(file1_path, file2_path, output_path)
        print("\nğŸ‰ æ•°æ®é›†åˆå¹¶å’Œåˆ†å‰²æˆåŠŸå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆå¹¶è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        raise

if __name__ == "__main__":
    main()
